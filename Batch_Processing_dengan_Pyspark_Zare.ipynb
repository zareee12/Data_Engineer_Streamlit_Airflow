{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMsPXK9z3FDb4jb7AzXTuR0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zareee12/Data_Engineer_Streamlit_Airflow/blob/main/Batch_Processing_dengan_Pyspark_Zare.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instalasi"
      ],
      "metadata": {
        "id": "GSQTpdGH5huC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xt4Y1Xaj4F_H",
        "outputId": "a04b37e9-d1ca-40b8-a095-2c1d8e35ab11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "openjdk version \"11.0.20.1\" 2023-08-24\n",
            "OpenJDK Runtime Environment (build 11.0.20.1+1-post-Ubuntu-0ubuntu122.04)\n",
            "OpenJDK 64-Bit Server VM (build 11.0.20.1+1-post-Ubuntu-0ubuntu122.04, mixed mode, sharing)\n"
          ]
        }
      ],
      "source": [
        "!java -version\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install pyspark\n",
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frraPZ675dOm",
        "outputId": "b70a6fa8-4c4d-4d64-b376-60af90e3839d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.4.1.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.1-py2.py3-none-any.whl size=311285387 sha256=34574f1bef73c2d1609feabe3bdd31fe38c32f56f03f28b4bdc9ac441457b505\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/77/a3/ff2f74cc9ab41f8f594dabf0579c2a7c6de920d584206e0834\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mendownload Data"
      ],
      "metadata": {
        "id": "3pVEZoIi53Dv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Download datasets\n",
        "from IPython.display import clear_output\n",
        "\n",
        "! wget https://raw.githubusercontent.com/databricks/Spark-The-Definitive-Guide/master/data/retail-data/all/online-retail-dataset.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fd3UwVUx6LGN",
        "outputId": "d8be5491-2063-428a-f22b-2f4033969ccb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-09-20 04:45:58--  https://raw.githubusercontent.com/databricks/Spark-The-Definitive-Guide/master/data/retail-data/all/online-retail-dataset.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 45038760 (43M) [text/plain]\n",
            "Saving to: ‘online-retail-dataset.csv’\n",
            "\n",
            "online-retail-datas 100%[===================>]  42.95M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-09-20 04:45:58 (343 MB/s) - ‘online-retail-dataset.csv’ saved [45038760/45038760]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"dibimbingDF\").getOrCreate()"
      ],
      "metadata": {
        "id": "oVRai6JI6_zz"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Operasi Kolom Tingkat Lanjut"
      ],
      "metadata": {
        "id": "9u8CBW_37QxR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Window Function"
      ],
      "metadata": {
        "id": "joNyjTZN7UWA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create dataframe\n",
        "data = [(\"John\", \"Sales\", 5000),\n",
        "        (\"Sara\", \"Engineering\", 6500),\n",
        "        (\"Chris\", \"Sales\", 5500),\n",
        "        (\"Rachel\", \"Engineering\", 6500),\n",
        "        (\"Maria\", \"Engineering\", 6000),\n",
        "        (\"Eric\", \"Sales\", 4500),\n",
        "        (\"Tom\", \"Engineering\", 7000),\n",
        "        (\"Kim\", \"Sales\", 4000),\n",
        "        (\"Mike\", \"Engineering\", 7500)]\n",
        "\n",
        "schema = [\"name\", \"department\", \"salary\"]"
      ],
      "metadata": {
        "id": "2YrYUQr_lCvQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z6IASgjH75B6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add rank and dense_rank columns\n",
        "from pyspark.sql.functions import rank, dense_rank, ntile, row_number, col\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "df = spark.createDataFrame(data, schema)\n",
        "\n",
        "w1 = Window().partitionBy(\"department\").orderBy(col(\"salary\").desc())\n",
        "df = (\n",
        "    df\n",
        "    .withColumn(\"rank\", rank().over(w1))\n",
        "    .withColumn(\"dense_rank\", dense_rank().over(w1))\n",
        "    .withColumn(\"ntile\", ntile(4).over(w1))\n",
        "    .withColumn(\"row_num\", row_number().over(w1))\n",
        ")"
      ],
      "metadata": {
        "id": "LfxV9n8Ims3g"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcvK5dxj7-mi",
        "outputId": "e41b0d9a-2dff-41fa-ee3e-da743aa52c4f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----------+------+----+----------+-----+-------+\n",
            "|  name| department|salary|rank|dense_rank|ntile|row_num|\n",
            "+------+-----------+------+----+----------+-----+-------+\n",
            "|  Mike|Engineering|  7500|   1|         1|    1|      1|\n",
            "|   Tom|Engineering|  7000|   2|         2|    1|      2|\n",
            "|  Sara|Engineering|  6500|   3|         3|    2|      3|\n",
            "|Rachel|Engineering|  6500|   3|         3|    3|      4|\n",
            "| Maria|Engineering|  6000|   5|         4|    4|      5|\n",
            "| Chris|      Sales|  5500|   1|         1|    1|      1|\n",
            "|  John|      Sales|  5000|   2|         2|    2|      2|\n",
            "|  Eric|      Sales|  4500|   3|         3|    3|      3|\n",
            "|   Kim|      Sales|  4000|   4|         4|    4|      4|\n",
            "+------+-----------+------+----+----------+-----+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, lead, lag, unix_timestamp\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "# create example dataset\n",
        "data = [\n",
        "    ('customer1', '2022-01-01 00:00:00'),\n",
        "    ('customer1', '2022-01-02 00:00:00'),\n",
        "    ('customer1', '2022-01-03 00:00:00'),\n",
        "    ('customer2', '2022-01-01 00:00:00'),\n",
        "    ('customer2', '2022-01-04 00:00:00'),\n",
        "    ('customer2', '2022-01-06 00:00:00'),\n",
        "]\n",
        "\n",
        "df = (\n",
        "    spark\n",
        "    .createDataFrame(data, ['customer', 'transaction_time'])\n",
        "    .withColumn('transaction_time_unix', unix_timestamp('transaction_time'))\n",
        ")\n",
        "\n",
        "# create window partitioned by customer and ordered by transaction_time\n",
        "w = Window.partitionBy('customer').orderBy('transaction_time_unix')\n",
        "\n",
        "(\n",
        "    df\n",
        " .withColumn('prev_transaction_time', lag('transaction_time_unix').over(w))\n",
        " .withColumn('next_transaction_time', lead('transaction_time_unix').over(w))\n",
        " .withColumn('time_gap', col('transaction_time_unix') - col('prev_transaction_time'))\n",
        " .withColumn('next_time_gap', col('next_transaction_time') - col('transaction_time_unix'))\n",
        " .show()\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YqX_ryE8vhy",
        "outputId": "cf21f669-f31e-4b46-f59d-b4216cdaaf42"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-------------------+---------------------+---------------------+---------------------+--------+-------------+\n",
            "| customer|   transaction_time|transaction_time_unix|prev_transaction_time|next_transaction_time|time_gap|next_time_gap|\n",
            "+---------+-------------------+---------------------+---------------------+---------------------+--------+-------------+\n",
            "|customer1|2022-01-01 00:00:00|           1640995200|                 null|           1641081600|    null|        86400|\n",
            "|customer1|2022-01-02 00:00:00|           1641081600|           1640995200|           1641168000|   86400|        86400|\n",
            "|customer1|2022-01-03 00:00:00|           1641168000|           1641081600|                 null|   86400|         null|\n",
            "|customer2|2022-01-01 00:00:00|           1640995200|                 null|           1641254400|    null|       259200|\n",
            "|customer2|2022-01-04 00:00:00|           1641254400|           1640995200|           1641427200|  259200|       172800|\n",
            "|customer2|2022-01-06 00:00:00|           1641427200|           1641254400|                 null|  172800|         null|\n",
            "+---------+-------------------+---------------------+---------------------+---------------------+--------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import sum, first, last, mean, stddev, window\n",
        "from pyspark.sql import Window\n",
        "\n",
        "# create a sample dataframe\n",
        "sales_data = [(\"Product A\", 100, \"2022-01-01 10:00:00\", \"Location 1\"),\n",
        "              (\"Product B\", 200, \"2022-01-01 11:00:00\", \"Location 1\"),\n",
        "              (\"Product A\", 150, \"2022-01-02 12:00:00\", \"Location 2\"),\n",
        "              (\"Product C\", 300, \"2022-01-03 14:00:00\", \"Location 2\"),\n",
        "              (\"Product D\", 250, \"2022-01-04 15:00:00\", \"Location 2\"),\n",
        "              (\"Product E\", 150, \"2022-01-05 16:00:00\", \"Location 3\"),\n",
        "              (\"Product F\", 180, \"2022-01-06 17:00:00\", \"Location 3\"),\n",
        "              (\"Product G\", 220, \"2022-01-07 18:00:00\", \"Location 3\")]\n",
        "\n",
        "sales_df = spark.createDataFrame(sales_data, [\"Product\", \"Price\", \"Sale Time\", \"Location\"])"
      ],
      "metadata": {
        "id": "OMgIIat79HKI"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define window specification to partition by location and order by sale time\n",
        "location_window_spec = Window.partitionBy(\"Location\").orderBy(\"Sale Time\")\n",
        "\n",
        "# calculate total sales revenue for each location over the entire duration of the dataset\n",
        "total_sales_revenue = sum(\"Price\").over(Window.partitionBy(\"Location\"))\n",
        "\n",
        "# calculate first and last sale date for each location\n",
        "first_sale_date = first(\"Sale Time\").over(location_window_spec)\n",
        "last_sale_date = last(\"Sale Time\").over(location_window_spec)\n",
        "\n",
        "# calculate average and standard deviation of the sale prices for each location\n",
        "average_sale_price = mean(\"Price\").over(location_window_spec)\n",
        "stddev_sale_price = stddev(\"Price\").over(location_window_spec)\n",
        "\n",
        "# add the calculated columns to the dataframe\n",
        "sales_df = (\n",
        "    sales_df\n",
        "    .withColumn(\"Total Sales Revenue\", total_sales_revenue)\n",
        "    .withColumn(\"First Sale Date\", first_sale_date)\n",
        "    .withColumn(\"Last Sale Date\", last_sale_date)\n",
        "    .withColumn(\"Average Sale Price\", average_sale_price)\n",
        "    .withColumn(\"Stddev Sale Price\", stddev_sale_price)\n",
        ")\n",
        "\n",
        "# show the results\n",
        "sales_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qsRfbyA9K_k",
        "outputId": "e813e3b3-b010-4dd5-e402-5e35d5dbb609"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----+-------------------+----------+-------------------+-------------------+-------------------+------------------+------------------+\n",
            "|  Product|Price|          Sale Time|  Location|Total Sales Revenue|    First Sale Date|     Last Sale Date|Average Sale Price| Stddev Sale Price|\n",
            "+---------+-----+-------------------+----------+-------------------+-------------------+-------------------+------------------+------------------+\n",
            "|Product A|  100|2022-01-01 10:00:00|Location 1|                300|2022-01-01 10:00:00|2022-01-01 10:00:00|             100.0|              null|\n",
            "|Product B|  200|2022-01-01 11:00:00|Location 1|                300|2022-01-01 10:00:00|2022-01-01 11:00:00|             150.0| 70.71067811865476|\n",
            "|Product A|  150|2022-01-02 12:00:00|Location 2|                700|2022-01-02 12:00:00|2022-01-02 12:00:00|             150.0|              null|\n",
            "|Product C|  300|2022-01-03 14:00:00|Location 2|                700|2022-01-02 12:00:00|2022-01-03 14:00:00|             225.0|106.06601717798213|\n",
            "|Product D|  250|2022-01-04 15:00:00|Location 2|                700|2022-01-02 12:00:00|2022-01-04 15:00:00|233.33333333333334| 76.37626158259734|\n",
            "|Product E|  150|2022-01-05 16:00:00|Location 3|                550|2022-01-05 16:00:00|2022-01-05 16:00:00|             150.0|              null|\n",
            "|Product F|  180|2022-01-06 17:00:00|Location 3|                550|2022-01-05 16:00:00|2022-01-06 17:00:00|             165.0|21.213203435596427|\n",
            "|Product G|  220|2022-01-07 18:00:00|Location 3|                550|2022-01-05 16:00:00|2022-01-07 18:00:00|183.33333333333334| 35.11884584284247|\n",
            "+---------+-----+-------------------+----------+-------------------+-------------------+-------------------+------------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# group the data by location and window the data by day to get daily aggregated sales data\n",
        "(\n",
        "    sales_df\n",
        "    .groupBy(window(\"Sale Time\", \"1 day\"))\n",
        "    .agg(sum(\"Price\").alias(\"Daily Sales Revenue\"))\n",
        "    .show(truncate=False)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfPqRros9O7Q",
        "outputId": "ea3ac829-4b41-49dd-91f2-457e28cb9f83"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------------------+-------------------+\n",
            "|window                                    |Daily Sales Revenue|\n",
            "+------------------------------------------+-------------------+\n",
            "|{2022-01-02 00:00:00, 2022-01-03 00:00:00}|150                |\n",
            "|{2022-01-01 00:00:00, 2022-01-02 00:00:00}|300                |\n",
            "|{2022-01-03 00:00:00, 2022-01-04 00:00:00}|300                |\n",
            "|{2022-01-04 00:00:00, 2022-01-05 00:00:00}|250                |\n",
            "|{2022-01-05 00:00:00, 2022-01-06 00:00:00}|150                |\n",
            "|{2022-01-06 00:00:00, 2022-01-07 00:00:00}|180                |\n",
            "|{2022-01-07 00:00:00, 2022-01-08 00:00:00}|220                |\n",
            "+------------------------------------------+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# group the data by location and window the data by day to get daily aggregated sales data\n",
        "(\n",
        "    sales_df\n",
        "    .groupBy(\"Location\", window(\"Sale Time\", \"1 day\"))\n",
        "    .agg(sum(\"Price\").alias(\"Daily Sales Revenue\"))\n",
        "    .show(truncate=False)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-1dB3BD9Sh5",
        "outputId": "861dae7f-3d33-4f70-b5b3-946865ce5e9d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------------------------------------------+-------------------+\n",
            "|Location  |window                                    |Daily Sales Revenue|\n",
            "+----------+------------------------------------------+-------------------+\n",
            "|Location 2|{2022-01-03 00:00:00, 2022-01-04 00:00:00}|300                |\n",
            "|Location 2|{2022-01-02 00:00:00, 2022-01-03 00:00:00}|150                |\n",
            "|Location 1|{2022-01-01 00:00:00, 2022-01-02 00:00:00}|300                |\n",
            "|Location 3|{2022-01-06 00:00:00, 2022-01-07 00:00:00}|180                |\n",
            "|Location 3|{2022-01-05 00:00:00, 2022-01-06 00:00:00}|150                |\n",
            "|Location 3|{2022-01-07 00:00:00, 2022-01-08 00:00:00}|220                |\n",
            "|Location 2|{2022-01-04 00:00:00, 2022-01-05 00:00:00}|250                |\n",
            "+----------+------------------------------------------+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# UDF"
      ],
      "metadata": {
        "id": "3ROYbKCl9VSu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, udf, pandas_udf\n",
        "from pyspark.sql.types import IntegerType\n",
        "\n",
        "# Create a sample dataframe\n",
        "df = spark.createDataFrame([(1, \"apple\"), (2, \"banana\"), (3, \"orange\"),\n",
        "                            (4, \"apple\"), (5, \"banana\"), (6, \"orange\"),\n",
        "                            (7, \"apple\"), (8, \"banana\"), (9, \"orange\"),\n",
        "                            (10, \"apple\")], [\"id\", \"fruit\"])"
      ],
      "metadata": {
        "id": "RiFWMAQs9YbW"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the UDF logic\n",
        "def string_length(s):\n",
        "    return len(s)\n",
        "\n",
        "# Define the Python UDF\n",
        "string_length_udf = udf(string_length, IntegerType())\n",
        "\n",
        "# Apply the Python UDF and display the result\n",
        "df1 = df.withColumn(\"length\", string_length_udf(col(\"fruit\")))\n",
        "df1.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqgIYeAP9j1m",
        "outputId": "47acb923-eb20-4848-b116-a5a3815f31d3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+------+\n",
            "| id| fruit|length|\n",
            "+---+------+------+\n",
            "|  1| apple|     5|\n",
            "|  2|banana|     6|\n",
            "|  3|orange|     6|\n",
            "|  4| apple|     5|\n",
            "|  5|banana|     6|\n",
            "|  6|orange|     6|\n",
            "|  7| apple|     5|\n",
            "|  8|banana|     6|\n",
            "|  9|orange|     6|\n",
            "| 10| apple|     5|\n",
            "+---+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pandas UDF\n"
      ],
      "metadata": {
        "id": "hNSIMy4N9p_6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define the Pandas UDF\n",
        "@pandas_udf(IntegerType())\n",
        "def string_length_pandas_udf(s: pd.Series) -> pd.Series:\n",
        "    return s.str.len()\n",
        "\n",
        "# Apply the Pandas UDF and display the result\n",
        "df2 = df.withColumn(\"length\", string_length_pandas_udf(col(\"fruit\")))\n",
        "df2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFQqxFzA9uyJ",
        "outputId": "0f2783db-37be-414e-d4f3-17133062e2a2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+------+\n",
            "| id| fruit|length|\n",
            "+---+------+------+\n",
            "|  1| apple|     5|\n",
            "|  2|banana|     6|\n",
            "|  3|orange|     6|\n",
            "|  4| apple|     5|\n",
            "|  5|banana|     6|\n",
            "|  6|orange|     6|\n",
            "|  7| apple|     5|\n",
            "|  8|banana|     6|\n",
            "|  9|orange|     6|\n",
            "| 10| apple|     5|\n",
            "+---+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Partition & Bucket"
      ],
      "metadata": {
        "id": "9mOyABG_-C-a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Cleanup\n",
        "\n"
      ],
      "metadata": {
        "id": "yVyhPWXA-FUd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, TimestampType, DoubleType\n",
        "from pyspark.sql.functions import to_timestamp, to_date\n",
        "\n",
        "\n",
        "schema = StructType([\n",
        "    StructField(\"InvoiceNo\", StringType(), True),\n",
        "    StructField(\"StockCode\", StringType(), True),\n",
        "    StructField(\"Description\", StringType(), True),\n",
        "    StructField(\"Quantity\", IntegerType(), True),\n",
        "    StructField(\"InvoiceDate\", StringType(), True),\n",
        "    StructField(\"UnitPrice\", DoubleType(), True),\n",
        "    StructField(\"CustomerID\", StringType(), True),\n",
        "    StructField(\"Country\", StringType(), True)\n",
        "])\n",
        "\n",
        "retail_df = (\n",
        "    spark\n",
        "    .read.csv('online-retail-dataset.csv',header=True, schema=schema)\n",
        "    .withColumn(\"InvoiceTime\", to_timestamp(\"InvoiceDate\", \"M/d/yyyy H:mm\"))\n",
        "    .withColumn(\"InvoiceDate\", to_date(\"InvoiceDate\", \"M/d/yyyy H:mm\"))\n",
        ")\n",
        "retail_df.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcfWs037-Klr",
        "outputId": "d359cf47-24cd-45ed-cfbe-42659abd67a0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+--------------------+--------+-----------+---------+----------+--------------+-------------------+\n",
            "|InvoiceNo|StockCode|         Description|Quantity|InvoiceDate|UnitPrice|CustomerID|       Country|        InvoiceTime|\n",
            "+---------+---------+--------------------+--------+-----------+---------+----------+--------------+-------------------+\n",
            "|   536365|   85123A|WHITE HANGING HEA...|       6| 2010-12-01|     2.55|     17850|United Kingdom|2010-12-01 08:26:00|\n",
            "|   536365|    71053| WHITE METAL LANTERN|       6| 2010-12-01|     3.39|     17850|United Kingdom|2010-12-01 08:26:00|\n",
            "|   536365|   84406B|CREAM CUPID HEART...|       8| 2010-12-01|     2.75|     17850|United Kingdom|2010-12-01 08:26:00|\n",
            "|   536365|   84029G|KNITTED UNION FLA...|       6| 2010-12-01|     3.39|     17850|United Kingdom|2010-12-01 08:26:00|\n",
            "|   536365|   84029E|RED WOOLLY HOTTIE...|       6| 2010-12-01|     3.39|     17850|United Kingdom|2010-12-01 08:26:00|\n",
            "|   536365|    22752|SET 7 BABUSHKA NE...|       2| 2010-12-01|     7.65|     17850|United Kingdom|2010-12-01 08:26:00|\n",
            "|   536365|    21730|GLASS STAR FROSTE...|       6| 2010-12-01|     4.25|     17850|United Kingdom|2010-12-01 08:26:00|\n",
            "|   536366|    22633|HAND WARMER UNION...|       6| 2010-12-01|     1.85|     17850|United Kingdom|2010-12-01 08:28:00|\n",
            "|   536366|    22632|HAND WARMER RED P...|       6| 2010-12-01|     1.85|     17850|United Kingdom|2010-12-01 08:28:00|\n",
            "|   536367|    84879|ASSORTED COLOUR B...|      32| 2010-12-01|     1.69|     13047|United Kingdom|2010-12-01 08:34:00|\n",
            "+---------+---------+--------------------+--------+-----------+---------+----------+--------------+-------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Partition"
      ],
      "metadata": {
        "id": "J_rwPLsl-amE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(\n",
        "    retail_df\n",
        " .write\n",
        " .mode(\"overwrite\")\n",
        " .partitionBy('InvoiceDate')\n",
        " .parquet(\"/content/spark/online-retail-partitioned\")\n",
        ")"
      ],
      "metadata": {
        "id": "nRwANk_J-dqq"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "partitioned_table = (\n",
        "    spark\n",
        "    .read\n",
        "    .parquet(\"/content/spark/online-retail-partitioned\")\n",
        ")"
      ],
      "metadata": {
        "id": "iCUSSSIM-sbv"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "partitioned_table.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8jW9CNa-ztC",
        "outputId": "be1e0406-f2cf-4e67-f3f6-ccf79bf7cd76"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- InvoiceNo: string (nullable = true)\n",
            " |-- StockCode: string (nullable = true)\n",
            " |-- Description: string (nullable = true)\n",
            " |-- Quantity: integer (nullable = true)\n",
            " |-- UnitPrice: double (nullable = true)\n",
            " |-- CustomerID: string (nullable = true)\n",
            " |-- Country: string (nullable = true)\n",
            " |-- InvoiceTime: timestamp (nullable = true)\n",
            " |-- InvoiceDate: date (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "partitioned_table.explain(mode=\"formatted\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qV4AZu4g-3x8",
        "outputId": "dc3a44b8-5d02-4b30-d78b-d087ab711fde"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Physical Plan ==\n",
            "* ColumnarToRow (2)\n",
            "+- Scan parquet  (1)\n",
            "\n",
            "\n",
            "(1) Scan parquet \n",
            "Output [9]: [InvoiceNo#477, StockCode#478, Description#479, Quantity#480, UnitPrice#481, CustomerID#482, Country#483, InvoiceTime#484, InvoiceDate#485]\n",
            "Batched: true\n",
            "Location: InMemoryFileIndex [file:/content/spark/online-retail-partitioned]\n",
            "ReadSchema: struct<InvoiceNo:string,StockCode:string,Description:string,Quantity:int,UnitPrice:double,CustomerID:string,Country:string,InvoiceTime:timestamp>\n",
            "\n",
            "(2) ColumnarToRow [codegen id : 1]\n",
            "Input [9]: [InvoiceNo#477, StockCode#478, Description#479, Quantity#480, UnitPrice#481, CustomerID#482, Country#483, InvoiceTime#484, InvoiceDate#485]\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bucket"
      ],
      "metadata": {
        "id": "MjO5UyFN-7JM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import hour\n",
        "\n",
        "\n",
        "(\n",
        "    retail_df\n",
        " .withColumn(\"Hour\", hour(\"InvoiceTime\"))\n",
        " .write\n",
        " .mode(\"overwrite\")\n",
        " .partitionBy(\"InvoiceDate\")\n",
        " .bucketBy(2, \"Hour\")\n",
        " .sortBy(\"InvoiceTime\")\n",
        " .option(\"path\", \"/content/spark/online-retail-bucketed\")\n",
        " .saveAsTable(\"retail_bucketed\")\n",
        ")"
      ],
      "metadata": {
        "id": "PoIE3vYy-9bC"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sekarang kita memiliki 2 berkas Parquet, bukan hanya 1."
      ],
      "metadata": {
        "id": "j8DR74QR_e4W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pandas API On Spark"
      ],
      "metadata": {
        "id": "CIbCblmK_gPy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark.pandas as ps\n",
        "\n",
        "retail_ps = retail_df.pandas_api()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvknjxxv_qyX",
        "outputId": "a55b61a4-83cb-4140-bb17-9dadd30ec8d2"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pyspark/pandas/__init__.py:50: UserWarning: 'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retail_ps.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "UTVs3j-b_uYY",
        "outputId": "ad81a4cc-6d38-4cdb-e5d4-8ba9958d50c7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pyspark/sql/pandas/conversion.py:251: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead\n",
            "  series = series.astype(t, copy=False)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  InvoiceNo StockCode                          Description  Quantity InvoiceDate  UnitPrice CustomerID         Country         InvoiceTime\n",
              "0    536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6  2010-12-01       2.55      17850  United Kingdom 2010-12-01 08:26:00\n",
              "1    536365     71053                  WHITE METAL LANTERN         6  2010-12-01       3.39      17850  United Kingdom 2010-12-01 08:26:00\n",
              "2    536365    84406B       CREAM CUPID HEARTS COAT HANGER         8  2010-12-01       2.75      17850  United Kingdom 2010-12-01 08:26:00\n",
              "3    536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6  2010-12-01       3.39      17850  United Kingdom 2010-12-01 08:26:00\n",
              "4    536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6  2010-12-01       3.39      17850  United Kingdom 2010-12-01 08:26:00"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>InvoiceNo</th>\n",
              "      <th>StockCode</th>\n",
              "      <th>Description</th>\n",
              "      <th>Quantity</th>\n",
              "      <th>InvoiceDate</th>\n",
              "      <th>UnitPrice</th>\n",
              "      <th>CustomerID</th>\n",
              "      <th>Country</th>\n",
              "      <th>InvoiceTime</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>536365</td>\n",
              "      <td>85123A</td>\n",
              "      <td>WHITE HANGING HEART T-LIGHT HOLDER</td>\n",
              "      <td>6</td>\n",
              "      <td>2010-12-01</td>\n",
              "      <td>2.55</td>\n",
              "      <td>17850</td>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>2010-12-01 08:26:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>536365</td>\n",
              "      <td>71053</td>\n",
              "      <td>WHITE METAL LANTERN</td>\n",
              "      <td>6</td>\n",
              "      <td>2010-12-01</td>\n",
              "      <td>3.39</td>\n",
              "      <td>17850</td>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>2010-12-01 08:26:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>536365</td>\n",
              "      <td>84406B</td>\n",
              "      <td>CREAM CUPID HEARTS COAT HANGER</td>\n",
              "      <td>8</td>\n",
              "      <td>2010-12-01</td>\n",
              "      <td>2.75</td>\n",
              "      <td>17850</td>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>2010-12-01 08:26:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>536365</td>\n",
              "      <td>84029G</td>\n",
              "      <td>KNITTED UNION FLAG HOT WATER BOTTLE</td>\n",
              "      <td>6</td>\n",
              "      <td>2010-12-01</td>\n",
              "      <td>3.39</td>\n",
              "      <td>17850</td>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>2010-12-01 08:26:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>536365</td>\n",
              "      <td>84029E</td>\n",
              "      <td>RED WOOLLY HOTTIE WHITE HEART.</td>\n",
              "      <td>6</td>\n",
              "      <td>2010-12-01</td>\n",
              "      <td>3.39</td>\n",
              "      <td>17850</td>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>2010-12-01 08:26:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aggregated_df = retail_ps.groupby(\"InvoiceDate\").agg({\"InvoiceNo\": \"count\"}).reset_index()\n",
        "aggregated_df.columns = [\"InvoiceDate\", \"InvoiceCount\"]\n",
        "aggregated_df[\"InvoiceDate\"] = aggregated_df[\"InvoiceDate\"].astype(\"datetime64[ns]\")"
      ],
      "metadata": {
        "id": "7Dc7sF6S_zaT"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aggregated_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "jVQ3qCLs_2Jx",
        "outputId": "ea37bb96-1b84-452d-fb74-d5a232f97015"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pyspark/sql/pandas/conversion.py:251: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead\n",
            "  series = series.astype(t, copy=False)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  InvoiceDate  InvoiceCount\n",
              "0  2011-01-30           722\n",
              "1  2011-05-06          2051\n",
              "2  2011-01-23           879\n",
              "3  2011-07-07          1940\n",
              "4  2011-07-18          2234"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>InvoiceDate</th>\n",
              "      <th>InvoiceCount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2011-01-30</td>\n",
              "      <td>722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2011-05-06</td>\n",
              "      <td>2051</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2011-01-23</td>\n",
              "      <td>879</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2011-07-07</td>\n",
              "      <td>1940</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2011-07-18</td>\n",
              "      <td>2234</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pyspark/sql/pandas/conversion.py:251: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead\n",
            "  series = series.astype(t, copy=False)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  InvoiceDate  InvoiceCount\n",
              "0  2011-01-30           722\n",
              "1  2011-05-06          2051\n",
              "2  2011-01-23           879\n",
              "3  2011-07-07          1940\n",
              "4  2011-07-18          2234"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>InvoiceDate</th>\n",
              "      <th>InvoiceCount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2011-01-30</td>\n",
              "      <td>722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2011-05-06</td>\n",
              "      <td>2051</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2011-01-23</td>\n",
              "      <td>879</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2011-07-07</td>\n",
              "      <td>1940</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2011-07-18</td>\n",
              "      <td>2234</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retail_ps[[\"UnitPrice\"]].plot.hist()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "f-evvrW1_94w",
        "outputId": "88b51cd3-5152-4671-a213-c87ac992ccf0"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"9aef81d2-ec66-4146-a91c-7f4cd90bddf7\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"9aef81d2-ec66-4146-a91c-7f4cd90bddf7\")) {                    Plotly.newPlot(                        \"9aef81d2-ec66-4146-a91c-7f4cd90bddf7\",                        [{\"hovertemplate\":\"variable=UnitPrice\\u003cbr\\u003evalue=%{text}\\u003cbr\\u003ecount=%{y}\",\"name\":\"UnitPrice\",\"text\":[\"[-11062.06, -6058.854)\",\"[-6058.854, -1055.648)\",\"[-1055.648, 3947.558)\",\"[3947.558, 8950.764)\",\"[8950.764, 13953.97)\",\"[13953.97, 18957.176)\",\"[18957.176, 23960.382)\",\"[23960.382, 28963.588)\",\"[28963.588, 33966.794)\",\"[33966.794, 38970.0]\"],\"x\":[-8560.456999999999,-3557.2509999999993,1445.9550000000008,6449.161000000001,11452.367,16455.573,21458.779000000002,26461.985000000004,31465.191000000003,36468.397],\"y\":[2.0,0.0,541864.0,33.0,6.0,3.0,0.0,0.0,0.0,1.0],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"barmode\":\"stack\",\"xaxis\":{\"title\":{\"text\":\"value\"}},\"yaxis\":{\"title\":{\"text\":\"count\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('9aef81d2-ec66-4146-a91c-7f4cd90bddf7');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}